{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM AutoAI-SDK Auto-Generated Notebook v1.14.1\n",
    "\n",
    "**Note:** Notebook code generated using AutoAI will execute successfully. If code is modified or reordered,   \n",
    "there is no guarantee it will successfully execute. This pipeline is optimized for the original dataset.  \n",
    "The pipeline may fail or produce sub-optimium results if used with different data. For different data,  \n",
    "please consider returning to AutoAI Experiments to generate a new pipeline. Please read our documentation   \n",
    "for more information:   \n",
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>  \n",
    "\n",
    "\n",
    "Before modifying the pipeline or trying to re-fit the pipeline, consider:   \n",
    "The notebook converts dataframes to numpy arrays before fitting the pipeline   \n",
    "(a current restriction of the preprocessor pipeline). The known_values_list is passed by reference   \n",
    "and populated with categorical values during fit of the preprocessing pipeline. Delete its members before re-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"content\"></a>\n",
    "## Notebook content\n",
    "\n",
    "This notebook contains steps and code to demonstrate AutoAI pipeline. This notebook introduces commands for getting data,  \n",
    "pipeline model, model inspection and testing.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Notebook goals\n",
    "\n",
    "-  inspection of trained pipeline via graphical vizualization and source code preview\n",
    "-  pipeline evaluation\n",
    "-  pipeline deployment and webservice scoring.\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Setup](#setup)         \n",
    "    a.  [AutoAI experiment metadata](#variables_definition)      \n",
    "2.\t[Pipeline inspection](#inspection)      \n",
    "    a.  [Get historical optimizer instance](#get_hist_and_train)      \n",
    "    b.  [Get pipeline model](#get_pipeline)      \n",
    "    c.  [Preview pipeline model as python code](#preview_model_to_python_code)      \n",
    "    d.  [Visualize pipeline model](#visualize_pipeline)      \n",
    "    e.  [Read training data](#train_read)        \n",
    "    f.  [Test pipeline model locally](#test_model)       \n",
    "3.\t[Pipeline refinery and testing (optional)](#refinery)  \n",
    "    a.  [Pipeline definition source code](#pipeline_definition)      \n",
    "    b.  [Lale library](#lale_library)      \n",
    "4.\t[Deploy and score](#scoring)       \n",
    "    a.  [Insert WML credentials](#wml_credentials)   \n",
    "    b.  [Create deployment](#deployment)      \n",
    "    c.  [Score webservice](#online_scoring)        \n",
    "    d.  [Delete deployment](#delete_deployment)       \n",
    "5.  [Authors](#authors)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "# Setup\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    " - `ibm_watson_machine_learning` installation\n",
    " - `autoai-libs` installation/upgrade\n",
    " - `lightgbm` or `xgboost` installation/downgrade if they are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: ibm-watson-machine-learning in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (1.0.38)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson-machine-learning) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: lomond in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson-machine-learning) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk==2.7.* in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson-machine-learning) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson-machine-learning) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson-machine-learning) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson-machine-learning) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: pandas<=1.0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-watson-machine-learning) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from lomond->ibm-watson-machine-learning) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-s3transfer==2.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-cos-sdk==2.7.*->ibm-watson-machine-learning) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-core==2.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-cos-sdk==2.7.*->ibm-watson-machine-learning) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-cos-sdk==2.7.*->ibm-watson-machine-learning) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->ibm-watson-machine-learning) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from requests->ibm-watson-machine-learning) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas<=1.0.5->ibm-watson-machine-learning) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas<=1.0.5->ibm-watson-machine-learning) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas<=1.0.5->ibm-watson-machine-learning) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk==2.7.*->ibm-watson-machine-learning) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autoai-libs\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c7/921bb1dc4f46c7401a13bf6e4705b069b1bd0e196955e96dde7c8398f07d/autoai_libs-1.12.3-44-cp37-cp37m-win_amd64.whl (729kB)\n",
      "Collecting pandas<1.0.0,>=0.24.2 (from autoai-libs)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/d0/1e8e60e61e748338e3a40e42f5dfeee63ccdecfc4f0894122b890bfb009a/pandas-0.25.3-cp37-cp37m-win_amd64.whl (9.2MB)\n",
      "Collecting numpy>=1.16.4 (from autoai-libs)\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/a5/24db9dd5c4a8b6c8e495289f17c28e55601769798b0e2e5a5aeb2abd247b/numpy-1.19.4-cp37-cp37m-win_amd64.whl (12.9MB)\n",
      "Collecting scikit-learn<0.23.2,>=0.20.3 (from autoai-libs)\n",
      "  Downloading https://files.pythonhosted.org/packages/70/8e/682770fc1da047bb56443150bfd8d87d850459cd7cc412a5311de3abaa4a/scikit_learn-0.23.1-cp37-cp37m-win_amd64.whl (6.8MB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2018.7)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn<0.23.2,>=0.20.3->autoai-libs)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn<0.23.2,>=0.20.3->autoai-libs) (1.1.0)\n",
      "Collecting joblib>=0.11 (from scikit-learn<0.23.2,>=0.20.3->autoai-libs)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas<1.0.0,>=0.24.2->autoai-libs) (1.12.0)\n",
      "Installing collected packages: numpy, pandas, threadpoolctl, joblib, scikit-learn, autoai-libs\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\n",
      "  Found existing installation: pandas 0.23.4\n",
      "    Uninstalling pandas-0.23.4:\n",
      "      Successfully uninstalled pandas-0.23.4\n",
      "  Found existing installation: scikit-learn 0.20.1\n",
      "    Uninstalling scikit-learn-0.20.1:\n",
      "      Successfully uninstalled scikit-learn-0.20.1\n",
      "Successfully installed autoai-libs-1.12.3 joblib-0.17.0 numpy-1.19.4 pandas-0.25.3 scikit-learn-0.23.1 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U autoai-libs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"variables_definition\"></a>\n",
    "### AutoAI experiment metadata\n",
    "\n",
    "This cell defines COS credentials required to retrieve AutoAI pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ibm_watson_machine_learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4a47374fd46e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# @hidden_cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mibm_watson_machine_learning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS3Connection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS3Location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m training_data_reference = [DataConnection(\n\u001b[0;32m      5\u001b[0m     connection=S3Connection(\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ibm_watson_machine_learning'"
     ]
    }
   ],
   "source": [
    "# @hidden_cell\n",
    "from ibm_watson_machine_learning.helpers import DataConnection, S3Connection, S3Location\n",
    "\n",
    "training_data_reference = [DataConnection(\n",
    "    connection=S3Connection(\n",
    "        api_key='DLq3j7PxPztdS5phTxI8_RammdTAXT5s3fiQB59vEuBN',\n",
    "        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n",
    "        endpoint_url='https://s3-api.us-geo.objectstorage.softlayer.net'\n",
    "    ),\n",
    "        location=S3Location(\n",
    "        bucket='diabetesprediction-donotdelete-pr-t66xgqn2dq1x74',\n",
    "        path='diabetes.csv'\n",
    "    ))\n",
    "]\n",
    "training_result_reference = DataConnection(\n",
    "    connection=S3Connection(\n",
    "        api_key='DLq3j7PxPztdS5phTxI8_RammdTAXT5s3fiQB59vEuBN',\n",
    "        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n",
    "        endpoint_url='https://s3-api.us-geo.objectstorage.softlayer.net'\n",
    "    ),\n",
    "    location=S3Location(\n",
    "        bucket='diabetesprediction-donotdelete-pr-t66xgqn2dq1x74',\n",
    "        path='auto_ml/9e2a4910-e87c-4a6b-b4b0-5d3f68cf90e0/wml_data/2aadd442-3a57-462c-b5e7-cccc0186b4b9/data/automl',\n",
    "        model_location='auto_ml/9e2a4910-e87c-4a6b-b4b0-5d3f68cf90e0/wml_data/2aadd442-3a57-462c-b5e7-cccc0186b4b9/data/automl/hpo_c_output/Pipeline1/model.pickle',\n",
    "        training_status='auto_ml/9e2a4910-e87c-4a6b-b4b0-5d3f68cf90e0/wml_data/2aadd442-3a57-462c-b5e7-cccc0186b4b9/training-status.json'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell contains input parameters provided to run the AutoAI experiment in Watson Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment_metadata = dict(\n",
    "   prediction_type='classification',\n",
    "   prediction_column='Outcome',\n",
    "   test_size=0.1,\n",
    "   scoring='accuracy',\n",
    "   project_id='a18d2d26-5465-4e3f-aa06-e0d704059222',\n",
    "   csv_separator=',',\n",
    "   random_state=33,\n",
    "   max_number_of_estimators=2,\n",
    "   training_data_reference = training_data_reference,\n",
    "   training_result_reference = training_result_reference,\n",
    "   deployment_url='https://us-south.ml.cloud.ibm.com')\n",
    "\n",
    "pipeline_name='Pipeline_4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"inspection\"></a>\n",
    "## Pipeline inspection\n",
    "In this section you will get the trained pipeline model from the AutoAI experiment and inspect it.  \n",
    "You will see pipeline as a pythone code, graphically visualized and at the end, you will perform a local test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"get_hist_and_train\"></a>\n",
    "### Get historical optimizer instance\n",
    "\n",
    "The next cell contains code for retrieving fitted optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.experiment import AutoAI\n",
    "\n",
    "optimizer = AutoAI().runs.get_optimizer(metadata=experiment_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"get_pipeline\"></a>\n",
    "### Get pipeline model\n",
    "\n",
    "The following cell loads selected AutoAI pipeline model. If you want to get pure scikit-learn pipeline specify `as_type='sklearn'` parameter. By default enriched scikit-learn pipeline is returned `as_type='lale'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model = optimizer.get_pipeline(pipeline_name=pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"preview_model_to_python_code\"></a>\n",
    "### Preview pipeline model as python code\n",
    "In the next cell, downloaded pipeline model could be previewed as a python code.  \n",
    "You will be able to see what exact steps are involved in model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model.pretty_print(combinators=False, ipython_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"visualize_pipeline\"></a>\n",
    "### Visualize pipeline model\n",
    "\n",
    "Preview pipeline model stages as graph. Each node's name links to detailed description of the stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"train_read\"></a>\n",
    "### Read training data\n",
    "\n",
    "Retrieve training dataset from AutoAI experiment as pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = optimizer.get_data_connections()[0].read()\n",
    "test_df = train_df.sample(n=5).drop([experiment_metadata['prediction_column']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"test_model\"></a>\n",
    "### Test pipeline model locally\n",
    "You can predict target value using trained AutoAI model by calling `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pipeline_model.predict(test_df.values)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"refinery\"></a>\n",
    "## Pipeline refinery and testing (optional)\n",
    "\n",
    "In this section you will learn how to refine and retrain the best pipeline returned by AutoAI.\n",
    "It can be performed by:\n",
    " - modifying pipeline definition source code\n",
    " - using [lale](https://lale.readthedocs.io/en/latest/) library for semi-automated data science\n",
    "\n",
    "**Note**: In order to run this section change following cells to 'code' cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_definition\"></a>\n",
    "### Pipeline definition source code\n",
    "Following cell lets you experiment with pipeline definition in python, e.g. change steps parameters.\n",
    "\n",
    "It will inject pipeline definition to the next cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "pipeline_model.pretty_print(combinators=False, ipython_display='input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"lale_library\"></a>\n",
    "### Lale library\n",
    "\n",
    "**Note**: This is only an exemplary usage of lale package. You can import more different estimators to refine downloaded pipeline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import estimators"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression as E1\n",
    "from sklearn.tree import DecisionTreeClassifier as E2\n",
    "from sklearn.neighbors import KNeighborsClassifier as E3\n",
    "from lale.lib.lale import Hyperopt\n",
    "from lale.operators import TrainedPipeline\n",
    "from lale import wrap_imported_operators\n",
    "from lale.helpers import import_from_sklearn_pipeline\n",
    "wrap_imported_operators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"decomposition_definition\"></a>\n",
    "#### Pipeline decomposition and new definition\n",
    "In this step the last stage from pipeline is removed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "prefix = pipeline_model.remove_last().freeze_trainable()\n",
    "prefix.visualize()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "new_pipeline = prefix >> (E1 | E2 | E3)\n",
    "new_pipeline.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"new_optimizer\"></a>\n",
    "#### New optimizer `hyperopt` configuration and training\n",
    "\n",
    "This section can introduce other results than the original one and it should be used\n",
    "by more advanced users.\n",
    "\n",
    "New pipeline is re-trained by passing train data to it and calling `fit` method.\n",
    "\n",
    "Following cell performs dataset split for refined pipeline model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X = train_df.drop([experiment_metadata['prediction_column']], axis=1).values\n",
    "train_y = train_df[experiment_metadata['prediction_column']].values\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_X, train_y, test_size=experiment_metadata['test_size'],\n",
    "                                                    stratify=train_y, random_state=experiment_metadata['random_state'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "hyperopt = Hyperopt(estimator=new_pipeline, cv=3, max_evals=20)\n",
    "fitted_hyperopt = hyperopt.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "hyperopt_pipeline = fitted_hyperopt.get_pipeline()\n",
    "new_pipeline = hyperopt_pipeline.export_to_sklearn_pipeline()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "prediction = new_pipeline.predict(test_X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_true=test_y, y_pred=prediction)\n",
    "print('accuracy_score: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"scoring\"></a>\n",
    "## Deploy and Score\n",
    "\n",
    "In this section you will learn how to deploy and score pipeline model as webservice using WML instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"wml_credentials\"></a>\n",
    "### Connection to WML\n",
    "Authenticate the Watson Machine Learning service on IBM Cloud.\n",
    "\n",
    "**Tip**: Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n",
    "\n",
    "**Note:** You can also get service specific apikey by going to the [**Service IDs** section of the Cloud Console](https://cloud.ibm.com/iam/serviceids).  From that page, click **Create**, then copy the created key and paste it below.\n",
    "\n",
    "**Action**: Enter your `api_key` in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api_key = \"PUT_YOUR_API_KEY_HERE\"\n",
    "\n",
    "wml_credentials = {\n",
    "  \"apikey\": api_key,\n",
    "  \"url\": experiment_metadata[\"deployment_url\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deployment\"></a>\n",
    "\n",
    "### Create deployment\n",
    " **Action**: If you want to deploy refined pipeline please change the `pipeline_name` to\n",
    "`new_pipeline`.\n",
    "If you prefer you can also change the `deployment_name`.\n",
    "\n",
    " **Action**: To perform deployment please specify `target_space_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_space_id = \"PUT_YOUR_TARGET_SPACE_ID_HERE\"\n",
    "\n",
    "from ibm_watson_machine_learning.deployment import WebService\n",
    "service = WebService(source_wml_credentials=wml_credentials,\n",
    "                     target_wml_credentials=wml_credentials,\n",
    "                     source_project_id=experiment_metadata['project_id'],\n",
    "                     target_space_id=target_space_id)\n",
    "service.create(\n",
    "model=pipeline_name,\n",
    "metadata=experiment_metadata,\n",
    "deployment_name=f'{pipeline_name}_webservice'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment object could be printed to show basic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to show all available information about deployment use `.get_params()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "service.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"online_scoring\"></a>\n",
    "### Score webservice\n",
    "You can make scoring request by calling `score()` on deployed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = service.score(payload=test_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to work with the webservice in external Python application you can retrieve the service object by:\n",
    " - initialize service by:\n",
    "```\n",
    " service = WebService(target_wml_credentials=wml_credentials,\n",
    "                      target_space_id=target_space_id)\n",
    "```\n",
    " - get deployment_id by `service.list()` method\n",
    " - get webservice object by `service.get('deployment_id')` method\n",
    "\n",
    "After that you can call `service.score()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"delete_deployment\"></a>\n",
    "### Delete deployment\n",
    "\n",
    "You can delete an existing deployment by calling `service.delete()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"authors\"></a>\n",
    "### Authors\n",
    "\n",
    "Licensed Materials - Copyright Â© 2020 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
    "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
    "\n",
    "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs  \n",
    "(or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms),  \n",
    "such agreements located in the link below. Specifically, the Source Components and Sample Materials clause  \n",
    "included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
    "\n",
    "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BHU2B7&title=IBM%20Watson%20Studio%20Auto-generated%20Notebook%20V2.1\">License Terms</a>  \n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
